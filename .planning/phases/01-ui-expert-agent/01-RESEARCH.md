# Phase 1: UI Expert Agent - Research

**Researched:** 2026-01-31
**Domain:** AI-powered design-to-code generation with Figma MCP + CrewAI + Streamlit
**Confidence:** MEDIUM

## Summary

UI Expert Agent, Figma tasarÄ±mlarÄ±ndan Streamlit component kodu Ã¼reten bir AI agent'tÄ±r. Bu agent, Figma MCP server aracÄ±lÄ±ÄŸÄ±yla tasarÄ±m verilerine eriÅŸecek, Gemini 2.0 Flash'Ä±n vision yeteneklerini kullanarak tasarÄ±mlarÄ± analiz edecek ve Ã¼retim kalitesinde Streamlit Python kodu Ã¼retecek.

AraÅŸtÄ±rma Ã¼Ã§ temel teknolojiyi kapsadÄ±: (1) Figma MCP server entegrasyonu (design context'e eriÅŸim iÃ§in), (2) CrewAI agent mimarisi (tool-based agent patterns iÃ§in), ve (3) Streamlit component yapÄ±sÄ± (output code structure iÃ§in). 2026'da bu alanda Ã¶nemli geliÅŸmeler var: Figma'nÄ±n resmi MCP server'Ä± beta'da, multimodal LLM'ler vision-to-code'da %90+ doÄŸruluk saÄŸlÄ±yor, ve AI-native component library yaklaÅŸÄ±mlarÄ± olgunlaÅŸmÄ±ÅŸ durumda.

Temel zorluk: AI code generation'da "hallucination" riski yÃ¼ksek. Bu yÃ¼zden agent'a verification mekanizmalarÄ±, reference component library, ve iterative refinement yetenekleri kazandÄ±rmak kritik.

**Primary recommendation:** Reference component library (mevcut Streamlit component Ã¶rnekleri) + RAG pattern + verification loop kullanarak hallucination'Ä± minimize et, production-ready kod Ã¼ret.

## Standard Stack

### Core

| Library | Version | Purpose | Why Standard |
|---------|---------|---------|--------------|
| CrewAI | 0.80+ | Multi-agent orchestration | Industry standard for role-based AI agents, 80/20 task-first design |
| Gemini 2.0 Flash | Latest | Vision-to-code model | Multimodal LLM with vision understanding, code generation, 1M token context window, Agentic Vision feature |
| Figma MCP Server | Beta | Design data access | Official Figma tool, MCP standard protocol, provides variables/components/layout data |
| Streamlit | 1.32+ | Target framework | Project's existing UI framework, component-based architecture |
| Pydantic | 2.x | Data validation | Type-safe skill inputs/outputs, CrewAI compatible |

### Supporting

| Library | Version | Purpose | When to Use |
|---------|---------|---------|-------------|
| streamlit-component-lib | Latest (v2) | Component building | Creating custom Streamlit components with Python-JS bridge |
| @streamlit/component-v2-lib | Latest | Frontend interface | TypeScript/React components for bidirectional communication |
| BaseTool (CrewAI) | Built-in | Custom tool creation | Class-based tools for complex logic with caching |
| @tool decorator (CrewAI) | Built-in | Simple functions as tools | Quick skill implementation for stateless operations |

### Alternatives Considered

| Instead of | Could Use | Tradeoff |
|------------|-----------|----------|
| Figma MCP | Figma REST API | MCP provides richer context + standardized protocol, REST requires manual parsing |
| Gemini 2.0 Flash | GPT-4 Vision / Claude 3.5 | Gemini has native code execution + Agentic Vision, better for iterative visual analysis |
| Reference Library | Pure prompt engineering | Reference library reduces hallucinations 6x (95% â†’ 15% error rate) |
| CrewAI | LangChain / AutoGen | CrewAI specializes in role-based agents, cleaner separation of concerns |

**Installation:**
```bash
pip install crewai>=0.80.0 streamlit>=1.32.0 pydantic>=2.0.0 google-generativeai
# Figma MCP already configured in project
```

## Architecture Patterns

### Recommended Project Structure

```
src/sade_agents/
â”œâ”€â”€ agents/
â”‚   â””â”€â”€ ui_expert.py              # UIExpertAgent (extends SadeAgent)
â”œâ”€â”€ skills/
â”‚   â”œâ”€â”€ design_skills.py          # Figma MCP interaction tools
â”‚   â””â”€â”€ codegen_skills.py         # Code generation + verification tools
â”œâ”€â”€ web/
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ reference/            # Reference component library
â”‚   â”‚   â”‚   â”œâ”€â”€ button.py         # Example: Streamlit button patterns
â”‚   â”‚   â”‚   â”œâ”€â”€ card.py           # Example: Card component
â”‚   â”‚   â”‚   â””â”€â”€ form.py           # Example: Form patterns
â”‚   â”‚   â””â”€â”€ generated/            # AI-generated components (gitignored?)
â”‚   â””â”€â”€ pages/
â”‚       â””â”€â”€ ui_generator.py       # Streamlit page for UI generation
â””â”€â”€ storage/
    â””â”€â”€ component_templates/      # Reusable component templates
```

### Pattern 1: Reference Component Library (HIGH PRIORITY)

**What:** Curated collection of "golden examples" showing AI what production-quality Streamlit code looks like.

**When to use:** Always. Reference libraries reduce AI errors from 95% to 15% (6x improvement).

**Example:**
```python
# src/sade_agents/web/components/reference/card.py
"""
Reference: Production-quality card component for Sade Chocolate.

This serves as a template for AI code generation.
Shows: Streamlit best practices, type hints, documentation.
"""
import streamlit as st
from typing import Optional

def render_card(
    title: str,
    content: str,
    icon: Optional[str] = None,
    variant: str = "default"
) -> None:
    """
    Renders a card component with Sade Chocolate styling.

    Args:
        title: Card heading
        content: Card body text
        icon: Optional emoji/icon
        variant: "default" | "primary" | "warning"
    """
    with st.container():
        col1, col2 = st.columns([1, 20])
        if icon:
            col1.markdown(f"### {icon}")
        col2.markdown(f"### {title}")
        col2.markdown(content)

# Usage example for AI training:
# render_card("Market Analysis", "Competitive insights...", icon="ðŸ“Š")
```

### Pattern 2: Tool-Based Design-to-Code Pipeline

**What:** Multi-step workflow using CrewAI tools, each handling one responsibility.

**When to use:** Complex transformations requiring multiple validation/refinement steps.

**Example:**
```python
# src/sade_agents/skills/design_skills.py
from crewai.tools import tool
from typing import Dict, Any

@tool
def fetch_figma_design(frame_url: str) -> Dict[str, Any]:
    """
    Fetches design data from Figma using MCP server.

    Uses: mcp__figma-desktop__get-frame-info

    Args:
        frame_url: Figma frame URL

    Returns:
        Design metadata: layout, components, variables, styles
    """
    # Call Figma MCP tool
    # Extract: dimensions, colors, spacing, typography, component hierarchy
    # Return structured design data
    pass

@tool
def generate_streamlit_code(design_data: Dict[str, Any], reference_examples: str) -> str:
    """
    Generates Streamlit component code from design data.

    Uses: Gemini 2.0 Flash with Agentic Vision + reference library

    Args:
        design_data: Structured Figma design info
        reference_examples: Code from reference component library

    Returns:
        Production-ready Streamlit Python code
    """
    # Prompt template with:
    # 1. Design specifications
    # 2. Reference component examples (RAG)
    # 3. Constraints: type hints, documentation, Sade styling
    # 4. Verification instructions: "check against reference patterns"
    pass

@tool
def verify_generated_code(code: str, design_data: Dict[str, Any]) -> Dict[str, Any]:
    """
    Verifies generated code meets requirements.

    Checks:
    - Syntax validity (ast.parse)
    - Type hints present
    - Matches design specs (layout, colors)
    - Follows reference patterns
    - No hardcoded values

    Returns:
        validation_result: pass/fail + issues found
    """
    pass
```

### Pattern 3: Iterative Refinement with Self-Review

**What:** Agent generates code, reviews it, identifies issues, regenerates until acceptable.

**When to use:** Production code generation where quality > speed.

**Example:**
```python
# src/sade_agents/agents/ui_expert.py
from sade_agents.agents.base import SadeAgent
from sade_agents.skills import fetch_figma_design, generate_streamlit_code, verify_generated_code

class UIExpertAgent(SadeAgent):
    """
    UI Expert - Figma to Streamlit code generator.

    Persona: Senior frontend developer with design system expertise.
    Specializes in: Component architecture, accessibility, responsive design.
    """

    def __init__(self) -> None:
        super().__init__(
            role="UI Expert - Design to Code Specialist",
            goal="Generate production-ready Streamlit components from Figma designs",
            tools=[
                fetch_figma_design,
                generate_streamlit_code,
                verify_generated_code,
            ],
            backstory="""
You are a UI Expert specializing in translating Figma designs to Streamlit code.

## Your Standards:
- Production-ready code only (no placeholders, no TODOs)
- Follow reference component library patterns EXACTLY
- Type hints on all functions
- Clear documentation
- Sade Chocolate brand consistency

## Your Process:
1. Analyze Figma design thoroughly
2. Generate code using reference examples
3. Self-review against design specs
4. Iterate until verification passes
5. Never deliver code with hallucinations

## Code Quality Rules:
- NEVER invent Streamlit APIs (use only documented methods)
- NEVER hardcode values (use variables/config)
- NEVER skip type hints or documentation
- ALWAYS match reference library patterns
            """,
            department="product",
            autonomy_level="supervised",  # Requires human review before deployment
            verbose=True,
        )
```

### Anti-Patterns to Avoid

- **God Tasks:** Don't create one mega-task "generate complete UI". Break into: analyze design â†’ generate skeleton â†’ add styling â†’ verify â†’ refine.

- **Ignoring Reference Library:** Pure prompt engineering without examples causes 95% error rate. ALWAYS provide reference code.

- **No Verification Loop:** Agent produces code once and assumes it's correct. Add self-review step.

- **Hardcoded Design Values:** Extracting colors/spacing from Figma then hardcoding them in generated code. Use Streamlit theming or variables.

- **Tool Hallucination:** Agent with no assigned tools invents fake tools. Explicitly assign tools list.

- **Overreliance on Context:** Dumping entire design file into context. Extract only relevant frame/component data.

## Don't Hand-Roll

Problems that look simple but have existing solutions:

| Problem | Don't Build | Use Instead | Why |
|---------|-------------|-------------|-----|
| Figma design data extraction | Custom Figma API client | Figma MCP server (mcp__figma-desktop__*) | Official tool, handles auth, provides standardized output, includes Make resources |
| Python-JavaScript bridge for Streamlit | Custom WebSocket/iframe | streamlit-component-lib v2 | Bidirectional data flow, handles serialization (JSON, Arrow), rerun lifecycle management |
| Code syntax validation | Regex/string parsing | ast.parse() (Python stdlib) | Catches syntax errors before execution, no external dependency |
| LLM response validation | String matching | Pydantic models + Gemini structured output | Type-safe, automatic validation, integration with CrewAI |
| Component state management | Global variables | st.session_state | Streamlit's official state system, works with reruns |
| Image/screenshot analysis | OpenCV preprocessing | Gemini 2.0 Agentic Vision | Built-in zoom/inspect/manipulate, code execution for vision tasks |

**Key insight:** 2026'da design-to-code iÃ§in mature tooling mevcut. Custom parser/converter yazmak deÄŸil, mevcut tools'u doÄŸru orchestrate etmek Ã¶nemli.

## Common Pitfalls

### Pitfall 1: AI Hallucination - Non-existent Streamlit APIs

**What goes wrong:** Agent invents Streamlit methods that don't exist (e.g., `st.card()`, `st.grid()`).

**Why it happens:** LLM training data + user expectations create "plausible but wrong" APIs.

**How to avoid:**
1. Reference library with ONLY real Streamlit code
2. Prompt instruction: "Use ONLY methods from reference examples"
3. Verification tool: Check generated code against Streamlit API docs
4. RAG: Inject Streamlit official docs into context

**Warning signs:**
- Generated code has methods not in reference library
- Verification tool catches undefined attributes
- Code runs but produces unexpected UI

### Pitfall 2: Absolute Positioning Hell

**What goes wrong:** Generated code uses pixel-perfect absolute positioning (divs with fixed widths/positions) instead of Streamlit's responsive layout system.

**Why it happens:** AI trained on HTML/CSS generates web-style code, not Streamlit-style declarative UI.

**How to avoid:**
1. Reference library emphasizes `st.columns()`, `st.container()`, `st.expander()`
2. Prompt constraint: "Use Streamlit layout containers, NO absolute positioning"
3. Design preparation: Use Figma Auto Layout (translates to responsive code)

**Warning signs:**
- Generated code has inline style dicts with width/height pixels
- UI breaks on mobile/different screen sizes
- Code doesn't use `st.columns()` or layout containers

### Pitfall 3: Bloated Generated Code

**What goes wrong:** AI generates 3000 lines for a simple form, with duplicated logic, unnecessary abstractions.

**Why it happens:** Overcomplex Figma design (each layer becomes a separate component) + AI's tendency to be verbose.

**How to avoid:**
1. Figma cleanup: Flatten unnecessary layers, use components/variants
2. Prompt instruction: "Generate minimal, DRY code. Reuse patterns."
3. Reference library shows concise examples
4. Post-generation review: Human simplifies if >200 lines

**Warning signs:**
- Generated file >500 lines for a simple UI
- Duplicated code blocks
- Nested abstractions with no benefit

### Pitfall 4: Missing Type Hints & Documentation

**What goes wrong:** Generated code lacks type annotations, docstrings, or comments.

**Why it happens:** AI prioritizes "working code" over "maintainable code" unless explicitly instructed.

**How to avoid:**
1. Reference library has 100% type hints + docstrings
2. Verification tool checks: presence of type hints, docstring format
3. Prompt instruction: "Follow Google Python style guide"

**Warning signs:**
- Functions have no `-> None` or return type
- No docstrings explaining parameters
- Mypy/Pylance shows type errors

### Pitfall 5: Ignoring Design System Constraints

**What goes wrong:** Generated code uses random colors/fonts instead of Sade Chocolate brand palette.

**Why it happens:** Agent doesn't know project's design tokens unless explicitly provided.

**How to avoid:**
1. Design tokens file: `brand_colors.py`, `typography.py`
2. Prompt includes: "Use colors from brand_colors.PALETTE"
3. Figma design uses Figma Variables (extracted via MCP, mapped to design tokens)

**Warning signs:**
- Hardcoded hex colors (`#FF5733`) instead of variables
- Fonts/sizes don't match brand guidelines
- Inconsistent spacing (random px values)

### Pitfall 6: Stale Knowledge Cut-off

**What goes wrong:** Agent suggests deprecated Streamlit patterns (e.g., `st.beta_columns`).

**Why it happens:** LLM trained on old Streamlit versions.

**How to avoid:**
1. Reference library uses ONLY current Streamlit APIs
2. Check Streamlit changelog for breaking changes
3. RAG: Inject latest Streamlit release notes

**Warning signs:**
- Generated code uses `st.beta_*` or `st.experimental_*` methods
- Deprecation warnings when running code

### Pitfall 7: No Context Management (Token Overflow)

**What goes wrong:** Agent tries to process entire Figma file (hundreds of frames), hits context limit.

**Why it happens:** Poor scoping - agent fetches all design data instead of specific frame.

**How to avoid:**
1. User selects specific Figma frame (not entire file)
2. MCP query scoped: `get-frame-info` for single frame
3. Incremental generation: One component at a time

**Warning signs:**
- MCP calls return massive JSON (>100KB)
- LLM context window errors
- Agent loses coherence mid-generation

## Code Examples

Verified patterns from official sources and current best practices:

### Example 1: Figma MCP Tool Integration

```python
# Source: Figma MCP Server documentation + CrewAI tool patterns
from crewai.tools import tool
from typing import Dict, Any

@tool
def extract_figma_frame(frame_url: str) -> Dict[str, Any]:
    """
    Extracts design specifications from a Figma frame using MCP.

    Uses Figma MCP server (mcp__figma-desktop__get-frame-info).

    Args:
        frame_url: Full Figma frame URL (e.g., https://figma.com/file/...)

    Returns:
        Design data:
        - layout: dimensions, spacing, alignment
        - components: hierarchy, types, properties
        - styles: colors, typography, effects
        - variables: design tokens

    Example:
        extract_figma_frame("https://figma.com/file/abc123/Frame-1")
        # Returns: {"layout": {...}, "components": [...], "styles": {...}}
    """
    # Implementation calls MCP server
    # Error handling: invalid URL, frame not found, permission denied
    # Output: Structured dict (Pydantic model) for next tool
    pass
```

### Example 2: Reference-Guided Code Generation

```python
# Source: AI code generation best practices 2026 + RAG patterns
from crewai.tools import tool
from pathlib import Path

@tool
def generate_component_code(
    design_spec: Dict[str, Any],
    component_type: str
) -> str:
    """
    Generates Streamlit component code using reference library.

    Args:
        design_spec: Design data from extract_figma_frame
        component_type: "card" | "form" | "table" | "button"

    Returns:
        Python code string (executable Streamlit component)

    Process:
    1. Load reference examples for component_type
    2. Construct prompt with design specs + reference code
    3. Call Gemini 2.0 Flash with structured output
    4. Return generated code
    """
    # Load reference
    reference_path = Path(f"src/sade_agents/web/components/reference/{component_type}.py")
    reference_code = reference_path.read_text()

    # Construct prompt
    prompt = f"""
Generate Streamlit component code based on this design and reference.

DESIGN SPECIFICATION:
{design_spec}

REFERENCE CODE (follow this pattern EXACTLY):
{reference_code}

CONSTRAINTS:
- Use ONLY Streamlit APIs shown in reference code
- Include type hints on all functions
- Add Google-style docstrings
- Use variables for colors/spacing (no hardcoded values)
- Maximum 200 lines

OUTPUT FORMAT: Python code only, no markdown or explanations.
"""

    # Call LLM with structured output
    # Return validated code
    pass
```

### Example 3: Code Verification Tool

```python
# Source: Python stdlib ast module + type checking best practices
from crewai.tools import tool
import ast
from typing import Dict, Any, List

@tool
def verify_streamlit_code(
    code: str,
    design_spec: Dict[str, Any]
) -> Dict[str, Any]:
    """
    Verifies generated Streamlit code meets quality standards.

    Args:
        code: Generated Python code string
        design_spec: Original design specifications

    Returns:
        Verification result:
        - valid: bool
        - issues: List[str] (empty if valid)
        - suggestions: List[str]

    Checks:
    1. Syntax validity (ast.parse)
    2. Type hints present
    3. No invented Streamlit APIs
    4. Matches design specs (colors, layout)
    5. No hardcoded values
    6. Documentation complete
    """
    issues: List[str] = []

    # 1. Syntax check
    try:
        ast.parse(code)
    except SyntaxError as e:
        issues.append(f"Syntax error: {e}")
        return {"valid": False, "issues": issues, "suggestions": []}

    # 2. Type hints check
    tree = ast.parse(code)
    functions = [node for node in ast.walk(tree) if isinstance(node, ast.FunctionDef)]
    for func in functions:
        if not func.returns:
            issues.append(f"Function '{func.name}' missing return type hint")

    # 3. Streamlit API check (no st.card, st.grid, etc.)
    valid_apis = ["st.write", "st.markdown", "st.columns", "st.container", ...]
    # Parse code, check all st.* calls against valid_apis

    # 4. Design spec matching (colors, dimensions)
    # Extract colors from code, compare with design_spec["styles"]["colors"]

    # 5. Hardcoded values check
    # Look for magic numbers, hex colors not from variables

    # 6. Documentation check
    # Verify docstrings present

    return {
        "valid": len(issues) == 0,
        "issues": issues,
        "suggestions": ["Add unit tests", "Consider accessibility"]
    }
```

### Example 4: Streamlit Component Template (Reference Library)

```python
# Source: Streamlit component best practices + Sade Chocolate style guide
"""
Reference: Data table component for market analysis results.

This is a REFERENCE for AI code generation.
Shows: Streamlit layout, type hints, Sade styling, documentation.
"""
import streamlit as st
import pandas as pd
from typing import Optional, Literal

def render_data_table(
    data: pd.DataFrame,
    title: str,
    variant: Literal["default", "compact", "striped"] = "default",
    show_download: bool = True,
) -> None:
    """
    Renders a styled data table for Sade Chocolate brand.

    Args:
        data: Pandas DataFrame to display
        title: Table heading
        variant: Display style
        show_download: Show CSV download button

    Example:
        df = pd.DataFrame({"Product": ["Ruby", "Dark"], "Price": [85, 65]})
        render_data_table(df, "Competitor Pricing", variant="striped")
    """
    # Header
    st.markdown(f"### {title}")

    # Table
    if variant == "compact":
        st.dataframe(data, use_container_width=True, height=300)
    elif variant == "striped":
        st.dataframe(data, use_container_width=True)
    else:
        st.table(data)

    # Download button
    if show_download:
        csv = data.to_csv(index=False).encode('utf-8')
        st.download_button(
            label="ðŸ“¥ CSV Ä°ndir",
            data=csv,
            file_name=f"{title.lower().replace(' ', '_')}.csv",
            mime="text/csv",
        )
```

## State of the Art

| Old Approach | Current Approach | When Changed | Impact |
|--------------|------------------|--------------|--------|
| Manual Figma API parsing | Figma MCP server | Q4 2025 | Standardized protocol, official support, Make integration |
| Screenshot â†’ GPT-4 Vision â†’ code | Screenshot â†’ Gemini Agentic Vision â†’ iterative code | Q1 2026 | 5-10% quality improvement, ability to zoom/inspect/manipulate images |
| Pure prompt engineering | Reference component library + RAG | 2025 | 6x error reduction (95% â†’ 15%) |
| Static components only | Bidirectional Streamlit components v2 | Streamlit 1.30+ | Real-time Python-JS communication |
| HTML/CSS/React generation | Framework-specific (Streamlit Python) | 2026 trend | Higher fidelity to target framework |

**Deprecated/outdated:**
- **Figma REST API for design-to-code:** MCP server now preferred (richer context, standardized)
- **st.experimental_* methods:** Graduated to stable API (st.columns, st.container, etc.)
- **Unstructured LLM outputs:** Replaced by structured output (Pydantic models, JSON mode)
- **Single-pass code generation:** Replaced by iterative refinement with verification loops

## Open Questions

Things that couldn't be fully resolved:

1. **Figma MCP Rate Limits for Production Use**
   - What we know: Starter plan = 6 tool calls/month, Pro plan = per-minute limits (same as Figma REST API Tier 1)
   - What's unclear: Exact per-minute limit numbers, whether batch requests are supported
   - Recommendation: Start with Pro plan, implement caching for design data, monitor MCP call frequency

2. **Gemini 2.0 Flash Context Window for Large Designs**
   - What we know: 1M token context window, supports multimodal (text + images)
   - What's unclear: Optimal image resolution for design analysis, how many Figma frames fit in context
   - Recommendation: Test with typical Figma frame sizes, use pagination if design is complex

3. **Streamlit Component v2 Stability**
   - What we know: v2 API is newer (`@streamlit/component-v2-lib`), supports modern React patterns
   - What's unclear: Migration path from v1, production readiness status
   - Recommendation: Use v2 for new components, check Streamlit release notes for breaking changes

4. **Component Library Maintenance Overhead**
   - What we know: Reference library dramatically improves AI accuracy
   - What's unclear: How often to update reference examples, how to version them
   - Recommendation: Treat as living documentation, update when Streamlit API changes, version control in git

5. **Multi-Component Generation Coordination**
   - What we know: Single component generation works well
   - What's unclear: How to generate cohesive multi-component layouts (e.g., entire page from Figma)
   - Recommendation: Start with single components, explore hierarchical generation (page â†’ sections â†’ components)

## Sources

### Primary (HIGH confidence)

- [Figma MCP Server Introduction](https://developers.figma.com/docs/figma-mcp-server/) - Official documentation
- [Figma MCP Server Guide](https://help.figma.com/hc/en-us/articles/32132100833559-Guide-to-the-Figma-MCP-server) - Help center article
- [Introducing Figma MCP Server](https://www.figma.com/blog/introducing-figma-mcp-server/) - Official blog post
- [CrewAI Crafting Effective Agents](https://docs.crewai.com/en/guides/agents/crafting-effective-agents) - Official best practices
- [CrewAI Tools Documentation](https://docs.crewai.com/en/concepts/tools) - Official tool integration guide
- [Streamlit Custom Components Intro](https://docs.streamlit.io/develop/concepts/custom-components/intro) - Official component docs
- [Streamlit Component Creation](https://docs.streamlit.io/develop/concepts/custom-components/create) - Official creation guide
- [Gemini 2.0 Flash Documentation](https://docs.cloud.google.com/vertex-ai/generative-ai/docs/models/gemini/2-0-flash) - Google Cloud docs
- [Agentic Vision in Gemini 3 Flash](https://blog.google/innovation-and-ai/technology/developers-tools/agentic-vision-gemini-3-flash/) - Official feature announcement

### Secondary (MEDIUM confidence)

- [Figma MCP Server Tested: Figma to Code in 2026](https://research.aimultiple.com/figma-to-code/) - Industry analysis (verified with official docs)
- [My LLM Coding Workflow Going Into 2026](https://addyosmani.com/blog/ai-coding-workflow/) - Expert practitioner guide (Addy Osmani, Google)
- [Reference Component Libraries for AI](https://31daysofvibecoding.com/2026/01/03/component-libraries-and-style-guides/) - Best practice guide (verified with multiple sources)
- [How to Build Reference Component Library](https://www.chatprd.ai/how-i-ai/workflows/how-to-build-an-on-brand-component-library-in-v0-using-screenshots) - Practical workflow guide
- [Prevent AI Hallucinations in Code](https://www.infoworld.com/article/3822251/how-to-keep-ai-hallucinations-out-of-your-code.html) - Industry best practices
- [CrewAI Best Practices (Medium)](https://ondrej-popelka.medium.com/crewai-practical-lessons-learned-b696baa67242) - Practitioner lessons (cross-verified with official docs)
- [Figma to Code Common Mistakes](https://www.locofy.ai/blog/design-best-practices) - Locofy design practices

### Tertiary (LOW confidence)

- WebSearch results on "design to code generation AI 2026" - General trend information, requires validation
- WebSearch results on "component library generation pattern AI 2026" - Emerging patterns, not yet standardized

## Metadata

**Confidence breakdown:**
- Standard stack: MEDIUM - Figma MCP is beta (official but new), CrewAI/Streamlit stable and verified
- Architecture: MEDIUM - Patterns sourced from official docs + verified practitioner guides, but project-specific implementation untested
- Pitfalls: MEDIUM - Common issues documented in multiple sources (Figma to code mistakes, AI hallucinations), but Streamlit-specific pitfalls partially inferred

**Research date:** 2026-01-31
**Valid until:** 2026-02-28 (30 days - fast-moving field, Figma MCP in beta, AI models updating frequently)

**Notes:**
- Figma MCP server is in BETA, expect API changes
- Gemini 3 Flash just released (January 2026) with Agentic Vision - very recent
- Reference component library pattern is mature but requires initial investment
- Verification protocol critical for production use (hallucination risk)
